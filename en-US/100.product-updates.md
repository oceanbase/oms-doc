# What's new

This topic describes the features of OceanBase Migration Service (OMS) Community Edition V4.1.1.

<main id="notice" type='notice'>
  <h4>Notice</h4>
  <p>OMS Community Edition V4.1.1 only supports direct deployment. It is not supported to upgrade to V4.1.1 from lower versions.</p>
</main>

## Support for Greenplum data sources

* You can import data from a Greenplum data source in PostgreSQL in Primary Database or Child Node mode.

  * Primary Database: OMS Community Edition reads schemas and data from the database in Greenplum master node mode.

  * Child Node: OMS Community Edition reads schemas and data from the database in segment node mode.

* You can migrate data only from a Greenplum 4 database.

* Schema migration, full migration, and full verification are supported. Incremental synchronization or reverse incremental migration is not supported.

## Compatibility with more message formats

* Maxwell format: You can synchronize data from OceanBase Database Community Edition to a Kafka instance in the Maxwell JSON format.

* Debezium format: You can synchronize data from OceanBase Database Community Edition to a Kafka or RocketMQ instance in the DebeziumFlatten or DebeziumSmt JSON format.

## Enhanced data synchronization

* Data synchronization to a Kafka instance: You can synchronize data in OceanBase Database Community Edition and DDL operations performed on user tables to a Kafka instance.

* Incremental data synchronization: If you select only incremental data synchronization, you can set timestamps for incremental data synchronization.

* Case sensitivity: You can migrate data from a MySQL database to OceanBase Database Community Edition in case-sensitive mode.

## Better ease of use

* API operations: 26 new API operations are provided to cover common features. For example, you can call the API operations to create and query data sources, and create, query, manage, and delete synchronization projects. By calling API operations, you can automatically schedule tasks in batches.

* Batch operations: Six common batch operations are added for managing data migration and synchronization projects. For example, you can batch start or stop projects. This greatly improves the efficiency of user operations and O&M project management.

* Incremental DDL operation migration or synchronization: You can create incremental DDL operation migration or synchronization projects by specifying objects using transfer lists.

   <main id="notice" type='notice'>
   <h4>Notice</h4>
   <p>All objects on which the DDL operations are performed must be selected as the synchronization objects. </p>
   </main>

* Performance monitoring for full data synchronization:

  * You can view the progress, estimated total number of rows, number of synchronized rows, records per second (RPS), and traffic in real time during full data synchronization.

  * New metrics are added to monitoring charts, including the RPS and synchronization traffic of the source database and destination database, average read time and average sharding time of the source database, and average write time of the destination database.

* Optimization of migration types: The default migration type for migrating data from a MySQL database to OceanBase Database Community Edition is changed to **All Tables**. This reduces the amount of time for loading selected migration objects when queries for tables with primary keys occupy background resources, and improves user experience.

* Optimization of information on user interfaces:

  * Long project names can be fully displayed.

  * Project names are added to alert information.

  * More basic information about data sources are added to connection details.

  * A Tips button and a failure message are displayed upon a schema migration failure.

  * The **Import CSV File** and **Download CSV Template** buttons are added at the bottom of the Import Object window.

* Optimization of forward switchover: During forward switchover, related Store files are deleted when the source Store component is stopped, and related information is cleared when the source Incr-Sync component is stopped. This avoids data security issues caused by unexpected data synchronization started by the components.

* Optimization of data source editing: You can change only the username and password of a database and only the AccessKey ID/AccessKey secret of a message object when you edit the information about a data source. This avoids errors caused by modifications to unsupported attributes.

* Optimization of precheck:

  * You can temporarily save project information upon a precheck failure for subsequent troubleshooting.

  * If the destination table does not exist or the engine type is not supported, you can remove the error table object.
