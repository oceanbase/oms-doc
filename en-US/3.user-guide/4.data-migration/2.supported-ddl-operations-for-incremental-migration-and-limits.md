# Supported DDL operations for incremental migration and limits

This topic describes the supported DDL operations in different types of incremental migration projects and their limits.

## Supported DDL operations and limits for incremental migration from a MySQL database to a MySQL tenant of OceanBase Database

> **Note:**
>
> If you have created an `index` in the source data source, it also exists in the destination data source. OceanBase Migration Service (OMS) automatically ignores the `index` without interrupting the migration process.

### Supported DDL operations for incremental migration

* CREATE statements

  * `create table`

      The CREATE TABLE statement supports the `IF NOT EXISTS` keyword and the `LIKE` option. Sample code:

      ```sql
      CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name
      { LIKE old_tbl_name | (LIKE old_tbl_name) }
      ```

      The CREATE TABLE statement cannot be used to create temporary tables or query-based tables. If you specify the `TEMPORARY` keyword, it will be ignored, and an empty string will be generated for a query-based table.

      Syntax of the CREATE TABLE statement:

      ```sql
      CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name
      (create_definition,...)   
      [table_options]
      [partition_options]
      ```

      | Category | Description |
      |-------------------|--------------------------------------------------------------|
      | create_definition | You can use this clause to perform the following operations: <ul><li> Create columns.   <li> Create indexes.   <li> Create FULLTEXT indexes.   <li> Create primary keys.   <li> Create unique keys.   <li> Create CHECK constraints.   <li> Create foreign keys.   <li> You cannot use this clause to create SPATIAL indexes. Otherwise, an empty string is generated.  </ul>  For column definition, this clause allows you to perform the following operations:<ul><li>  Use the GENERATED ALWAYS AS (expr) syntax to create a generated column, and specify VIRTUAL \| STORED.   <li>  Specify the NOT NULL \| NULL option.   <li>  Specify default values. The expression can be a common function, operator, or constant.   <li>  Specify the VISIBLE \| INVISIBLE option.   <li>  Specify AUTO_INCREMENT.   <li>  Specify the UNIQUE KEY/PRIMARY KEY option.   <li> Specify COMMENT.   <li> Specify COLLATE.   <li>  Specify foreign keys. <br>Specify ON DELETE \| ON UPDATE<br>. You cannot use this clause to specify the MATCH FULL \| MATCH PARTIAL \| MATCH SIMPLE option, which will be ignored.   <li> Specify CHECK constraints.   <li> You cannot use this clause to specify the [NOT] ENFORCED option, which will be ignored.  </ul> |
      | table_options | You can this clause to specify only table-level comments. |
      | partition_options | <ul><li>You can this clause to create LIST, RANGE, HASH, and KEY partitions.<br>For a LIST partition, you can specify a function partitioning key or column partitioning key.<br>For a RANGE partition, you can specify a function partitioning key or column partitioning key.<br>For a HASH partition, you can specify a function partitioning key or column partitioning key, and define LINEAR HASH.<br>For a KEY partition, you can specify a column partitioning key and define LINEAR KEY.   <li> You can use this clause to create HASH and KEY subpartitions.   <li> You can specify PARTITIONS number and SUBPARTITIONS number.      </ul> |

  * `create index`

* `ALTER TABLE`

  * Supported ADD operations

      | Operation | Description |
      |----------------|----------------------------------------------------------------------------|
      | ADD COLUMN | <ul><li> Adds a single column.   <li> Adds multiple columns.  <li>Supports <br>`add column [FIRST \| AFTER] col_name`.     </ul> |
      | ADD INDEX | <ul><li> Supports prefix indexes.  <li> Supports fulltext indexes.   <li>Supports SPATIAL indexes.   <li>Does not support function indexes (for which empty statements will be generated).   <li> Does not support the (asc \| desc) option for specifying the index direction, which will be ignored.   <li>Does not support the index_type: USING {BTREE \| HASH} option, which will be ignored.   <li>Does not support the index_option option, which will be ignored. </ul> |
      | ADD PRIMARY KEY | <ul><li> Supports prefix indexes.   <li> Does not support function indexes (for which empty statements will be generated).   <li> Does not support the (asc \| desc) option for specifying the index direction, which will be ignored.   <li> Does not support the index_type: USING {BTREE \| HASH} option, which will be ignored.  <li> Does not support the index_option option, which will be ignored.   </ul> |
      | ADD UNIQUE KEY | <ul><li> Supports prefix indexes.   <li>Does not support function indexes (for which empty statements will be generated).   <li>Does not support the (asc \| desc) option for specifying the index direction, which will be ignored.   <li>Does not support the index_type: USING {BTREE \| HASH} option, which will be ignored.   <li>Does not support the index_option option, which will be ignored.   </ul> |
      | ADD FOREIGN KEY | <ul><li>Supports ON DELETE \| ON UPDATE reference_option.  <li> You cannot use this clause to specify the MATCH FULL \| MATCH PARTIAL \| MATCH SIMPLE option, which will be ignored.  </ul> |

  * Unsupported ADD operations

      You cannot use the ALTER TABLE statement to add CHECK constraints. Otherwise, an empty statement will be generated.

  * Supported DROP operations

      | Operation | Sample statement |
      |----------|----------------------------------------------------------------------------------|
      | DROP COLUMN | ```alter table t DROP [COLUMN] col_name``` |
      | DROP INDEX | ```alter table t DROP {INDEX \| KEY} index_name``` |

  * Unsupported DROP operations

      | Operation | Sample statement |
      |-----------------|------------------------------------------------------------------------------|
      | DROP CONSTRAINT (for which an empty statement will be generated) | ```alter table t drop constraint c1``` |
      | DROP CHECK (for which an empty statement will be generated) | ```alter table t drop check c1``` |
      | DROP PRIMARY KEY (for which an empty statement will be generated) | ```alter table t DROP PRIMARY KEY``` |
      | DROP FOREIGN KEY | ```alter table t DROP FOREIGN KEY fk_symbol``` |

  * Supported ALTER operations

      | Operation | Description |
      |--------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
      | Modify table comments | ```alter table t comment = 'table comment'``` |
      | Modify fields | <ul><li> Supports modification of the default value of a field.   <li>Allows you to drop the default value of a field.   <li> Supports the modify syntax.   <li> Allows you to change the table name.  </ul> |

  * Unsupported ALTER operations

      | Operation | Description |
      |---------------------|------------------------------------------------------------------------------------------------------------|
      | RENAME COLUMN | ```alter table t  RENAME COLUMN old_col_name TO new_col_name``` |
      | RENAME INDEX | ```alter table t RENAME {INDEX \| KEY} old_index_name TO new_index_name``` |
      | Modify the VISIBLE attribute of a column | ```alter table t ALTER COLUMN col_name SET {VISIBLE \| INVISIBLE}``` |
      | Modify whether a constraint or CHECK constraint takes effect | ```alter table t ALTER {CHECK \| CONSTRAINT} symbol [NOT] ENFORCED``` |
      | Modify the VISIBLE attribute of an index | ```alter table t ALTER INDEX index_name {VISIBLE \| INVISIBLE}``` |
      | Modify whether an index takes effect | ```alter table t {DISABLE \| ENABLE} KEYS``` |
      | Set the collation for the character set of a table | ```alter table t [DEFAULT] CHARACTER SET [=] charset_name [COLLATE [=] collation_name]``` |
      | Modify the collation for the character set of a table | ```alter table t CONVERT TO CHARACTER SET charset_name [COLLATE collation_name]``` |
      | Others | <ul><li> Set ALGORITHM <br>```alter table t ALGORITHM [=] {DEFAULT \| INSTANT \| INPLACE \| COPY}```   <li> Set DISCARD \| IMPORT TABLESPACE <br>```alter table t {DISCARD \| IMPORT} TABLESPACE```   <li> Set FORCE<br> ```alter table t FORCE```   <li> Set the  LOCK attribute <br>```alter table t LOCK [=] {DEFAULT \| NONE \| SHARED \| EXCLUSIVE}```   <li> Set VALIDATION<br>```alter table t {WITHOUT \| WITH} VALIDATION``` </ul>|

* DROP statements

  * `drop table`

      You can use the DROP TABLE statement to drop a single table or multiple tables, but you cannot use this statement to drop a temporary table or specify the IF EXISTS or RESTRICT \| CASCADE keyword, whichc will be ignored during execution.

      ```sql
      DROP [TEMPORARY] TABLE [IF EXISTS]
      tbl_name [, tbl_name] ...
      [RESTRICT | CASCADE]
      ```

  * `drop index`

      The DROP INDEX statement does not support algorithm_option or lock_option, which will be ignored during execution.

      ```sql
      DROP INDEX index_name ON tbl_name
          [algorithm_option | lock_option] ...

      algorithm_option:
          ALGORITHM [=] {DEFAULT | INPLACE | COPY}

      lock_option:
          LOCK [=] {DEFAULT | NONE | SHARED | EXCLUSIVE}
      ```

* `rename table`

   You can use the RENAME TABLE statement to rename a single table or multiple tables.

   ```sql
   RENAME TABLE
   tbl_name TO new_tbl_name
   [, tbl_name2 TO new_tbl_name2] ...
   ```

* `truncate table`

   ```sql
   TRUNCATE [TABLE] tbl_name
   ```

### Limits of DDL operations

* If the table to be synchronized involves DDL operations that are not supported, the migration may fail and unrecoverable data exceptions may be caused.

* Frequent DDL operations on a table are not supported. After the Store finishes a DDL operation, which can be determined by the checkpoint, it proceeds to the next DDL operation. Otherwise, the Store may exit unexpectedly or cause unrecoverable data exceptions.

* Make sure that no DDL operations are performed before you create a Store and during the start of the Store. If log pulling is involved, make sure that no DDL operations are performed between the start time of pulling and the current time. Otherwise, the Store may exit unexpectedly or cause unrecoverable data exceptions.

* The table names before and after the `rename table` statement must be both included or both not included in the list of tables to be synchronized.

* If you enable DDL operations for incremental data migration, the `drop index` command is executed on all indexes, which may cause index loss in the destination database.

* In a DDL operation for incremental migration, if the primary key of a table is data of the FLOAT or DOUBLE type, data inconsistency may occur.

* If you use gh-ost to synchronize DDL operations for incremental migration from a MySQL database to an OceanBase database in MySQL tenant mode:

  * When you select **Specify Objects**, do not select the table named "\*_ghc".

  * When you select **Match Rules**, set **Object Exclusion Rule** to {database_name}.\*_ghc.

## Supported DDL operations for incremental migration from a MySQL tenant of OceanBase Database to a MySQL database and limits

OMS supports MySQL 5.5, 5.6, 5.7, and 8.0.

* Supported DDL operations for incremental migration

  * `create table`

    **Note**

    `create table` supports foreign key constraints.

  * `drop table`
  
  * `truncate table`

  * `alter table change column`

  * `alter table add column`

  * `alter table modify column`

    **Notice**

    You can only extend the field length. You cannot modify the field type.

  * `alter table alter column set default` or `alter table alter column drop default`

  * `alter table drop column`

  * `create index` or `alter table add index`

  * `drop index` or `alter table drop index`

* Limits of DDL operations

  * If the table to be synchronized involves DDL operations that are not supported, the migration may fail and cause unrecoverable data exceptions.

  * Frequent DDL operations on a table are not supported. After the Store finishes a DDL operation, which can be determined by the checkpoint, it proceeds to the next DDL operation. Otherwise, the Store may exit unexpectedly or cause unrecoverable data exceptions.

  * Make sure that no DDL operations are performed before you create a Store and during the start of the Store. If log pulling is involved, make sure that no DDL operations are performed between the start time of pulling and the current time. Otherwise, the Store may exit unexpectedly or cause unrecoverable data exceptions.

  * The tables before and after the `rename table` statement must be those to be synchronized or those do not require synchronization.

  * If you enable DDL operations for incremental data migration, the `drop index` command is executed on all indexes, which may cause index loss in the destination database.

## FAQ

Q: What can I do if a data migration project fails because I have performed an unsupported DDL operation in the source database?

A: Configure the DDL operation in SkipDDL and restart the data migration project. Procedure:

1. Go to the details page of the target project.

   1. Log on to the OMS console.

   2. In the left-side navigation pane, click `Data Migration`.

   3. In the **Migration Projects** list, click the name of the target project to go to its details page.

2. Click **View Component Monitoring** in the upper-right corner.

3. On the **View Component Monitoring** page, click **...** for the JDBCWriter component and choose **View Logs** from the short-cut menu.

4. Find the error DDL statement in the `error.log` file.

5. In the `ddl_msg.log` file, copy the content in `receive ddl:`.

6. Update component parameters.

   1. Return to the **View Component Monitoring** page and click **Update** for the JDBCWriter component.

   2. On the **Update Configurations** page, move the pointer over the `JDBCWriter.coordinatorFile.skipDdl` parameter. Click the Edit icon, change the value to the copied content, and click the Confirm icon. Multiple DDL statements must be separated with ampersands (\&). You can also change the delimiter.

   3. Move the pointer over the `extraConfig` parameter. Click the Add icon, add the `JDBCWriter.coordinatorFile.skipDDLSeparator = "$"` parameter, and click the Confirm icon. The default value of the new parameter is \&.

   4. Click **Update**.

7. Return to the details page of the data migration project, and click **Restore** in the upper-right corner to run the project again.
