# Incr-Sync/Full-Import 调优

## 名词解释

* TPS
  
    源端每秒拉取到的消息数量。

* 延时

    当前任务的延时时长，单位为秒。延时计算不考虑安全位点。

* ReadQ

    在异步传输时，中间框架通过 ReadQ 获取数据并将数据写入目标端。当前进程未被中间框架获取的数据将被缓存在 ReadQ 中。ReadQ 的默认最大值是 4096。如果值比较小，说明源端可能没有数据或者源端拉取存在瓶颈。

* WriteConsume

    写入一次 `{batch.size}` 的时间，单位毫秒。`WriteConsume` 的数值越低，说明目标端性能越好。

## 查询 Metrics 信息

执行 `./connector_utils.sh metrics` 命令，即可查询 Metrics 信息。

```bash
./connector_utils.sh metrics

2022-09-22 12:49:48.876
SOURCE: [RPS:0.0, IOPS:0.0M, delay:1489ms]
SINK: [RPS:0.0, TPS:0.0, IOPS:0.0M, delay:2986440ms]
SINK_TIME: [execute_time:0.0ms/record, commit_time:0.0ms/batch]
SINK_SLOW_ROUTES:
SINK_THREAD: 4/4
DISPATCHER: wait record:0, ready batch:0, shardTime:nullms/record
forward_slot0 batchAccumulate: 0, recordAccumulate: 0
queue_slot1 batchAccumulate: 0, recordAccumulate: 0
heap:620M/1945M, noHeap:52M/488M, threadCount:18, cpu:0.054, sysCpu:51.555
ParNew(count:0, cost:0) ConcurrentMarkSweep(count:0, cost:0)
```

说明如下：

1. SOURCE RPS/IOPS/DELAY

2. SINK RPS/TPS(RecordBatch/s)/IOPS/DELAY

3. SINK_TIME: execute_time 表示每个 record 的执行时间，commit_time 表示 recordBatch 的执行时间。

4. SINK_SLOW_ROUTES：内部统计下，部分执行较慢的 SINK_ROUTES 信息，SINK_ROUTE 表示可并行写入单元。例如，kafka 的 partition、datahub 的 shard、rocketmq 的队列。

5. SINK_THREAD：当前活跃 sinkThread / 最大 sinkThread。如果 sinkThread 较少证明 sink 端较为空闲，未达到瓶颈。

6. DISPATCHER 中间队列情况，wait record: 表示等待被分配的消息数，ready batch 表示等待 sink thread 执行的 record batch 数量。

    如果 wait record 数量较多，证明消息数量较大，可能受到 GC 影响。

    如果 ready batch 较多，则证明 sink 端存在瓶颈，可以尝试提高 sink 写入速率（例如，增加线程）。

7. {框架队列名称} batchAccumulate: {积攒 recordBatch 数量}, recordAccumulate: {积攒 record 数量}。

   1. 如果第一个队列 batchAccumulate 为空则证明当前瓶颈在 source 端无消息进入。

   2. 如果最后一个队列 batchAccumulate 满则证明瓶颈在 RecordDispatcher(冲突矩阵/散列) 中，此时需要看 DISPATCHER 的 metrics。

8. 堆内存使用/堆内存最大，非堆内存使用/非堆内存最大，线程数，进程 cpu && sys cpu。

9. {时间} {youngGcName}(count:{累计次数}, cost:{累计耗时}) {fullGcName}(count:{累计次数}, cost:{累计耗时})。

## 诊断 Incr-Sync/Full-Import

在 Incr-Sync/Full-Import 目录下执行 `./connector_utils.sh diagnose`，即可对 Incr-Sync/Full-Import 进行诊断。

```bash
./connector_utils.sh diagnose -s 'YYYY-MM-DDTHH:mm:ss' -e 'YYYY-MM-DDTHH:mm:ss'
```

上述命令中，`-s` 和 `-e` 均为可选参数，`-s` 表示开始分析日志的时间，`-e` 表示结束分析日志的时间。时间格式为 'YYYY-MM-DDTHH:mm:ss'，例如 '2023-06-01T12:00:00'。

`./connector_utils.sh diagnose` 的默认值为 10 分钟（`-e` 默认值为当前时间）。

返回结果示例如下：

```bash
[Metrics]
TPS: [last:345,avg:277.28,p99:911.00]
RPS: [last:106,avg:257.08,p99:968.00]
IOPS: [last:2KB,avg:21.33KB]
EXECUTE_TIME: [last:34ms,avg:220.44ms,p99:783.00ms]
SINK_DELAY: [last:19ms,avg:260.31ms,p99:819.00ms]
SOURCE_DELAY: [
 source_subtopic2_source_delay: [last:702ms,avg:525.00ms,p99:986.00ms]
 source_subtopic1_source_delay: [last:14ms,avg:490.69ms,p99:973.00ms]
]
QUEUE_BATCH_ACCUMULATE: [
 frame_queue_slot_1.batchAccumulate: [last:420,avg:496.00,p99:975.00]
 frame_queue_slot_2.batchAccumulate: [last:310,avg:470.05,p99:975.00]
]
JVM-MEM: heap:34.28M/3641M, noHeap:19.38M/0M]
THREAD: [count:4, sink:14/16]
CPU: [last:17,avg:27.95,p99:62.00]
[Pref]
sink block: true
youngGc: true
[Suggest]
config[coordinator.shuffleMinBatchSize]:20 to 40
config[coordinator.shuffleMaxBatchSize]:40 to 80
jvm to: -Xmx4096m 
```

说明如下：

1. Metrics 信息为判断依据。

2. Pref 信息为根据 Metrics 判断分析的瓶颈点。

3. Suggest 信息是推进优化的点，比如上述示例中可以更改 `coordinator.shuffleMinBatchSize`、`coordinator.shuffleMaxBatchSize` 与 jvm 配置项。

## workerNum

* `workerNum` 打满，`metrics` 日志中 `sink` 的 `executeTime` 和 `commitTime` 的时间可以接受。

  * 迁移：根据机器资源，修改 `JDBCWriter.worker_num` 增大 `workerNum` 的值。

  * 同步：根据机器资源，修改 `sink.workerNum` 增大 `workerNum` 的值。按照以下步骤修改 `workerNum` 的值：项目详情 -> 组件监控 -> Connector 更新 -> 在 sink 处新增参数 workerNum，并填写值后再单击更新。

* `workerNum` 没打满，`metrics` 日志中每两次之间的 GC 时间很长。

  迁移：`JDBCWriter.tx_records_limit` 默认为 `128`。将此参数调小，例如 `4`。

* `workerNum` 只有 `1` 或 `2`，`connector.log` 打印 `conflictKey` 或者 `deepSize` 关键字。
  
    迁移：新增 `JDBCWriter.coordinatorFile.hotKeyMerge = true`。

## GC 时间过长

  <main id="notice" type='explain'>
    <h4>说明</h4>
    <p>此处 GC 时间过长，指每秒 Young GC 超过 300ms，每秒都存在 Full GC。</p>
  </main>

### 查看 GC

在 `task` 目录下执行以下命令，查看每秒的 GC 的详情：

```bash
/opt/alibaba/java/bin/jstat -gcutil `cat task.pid` 1s 
```

* 增大 JVM 内存：调整 `coordinator.connectorJvmParam` 为 `-Xms12g`。

  `-Xmx16g` 仅为示例，您需要参考当前机器的内存调整。 如果之前参数存在，您可以去掉 `-Xmn`。
  
* 同步 && 全量：减少 `coordinator.bridgeQueueSize` 的值，默认是 `256`，可以减少到 `32`。

* 同步 Kafka：设置 `sink.lingerMs = 1`。

* 限制内存：`coordinator.throttleMemoryBound={bytes 字节数}`。建议将此参数设置为最大内存的 1/4。
  
  例如，最大堆内存是 16G，则该值为 `16 * 1024 * 1024  * 1/4 = 4294967296`。

* 如果 `conf/coordinator.json` 或者 `conf_new/coordinator.json` 中 `dispatcherClassName` 配置项是 `ShuffleRecordDispatcher`，则可以更改 `coordinator` 的如下配置项：
  
  * `maxRecordCapacity = 1000` 控制 `dispatcher` 队列总数。默认是根据 `shuffleMinBatchSize *(shuffleBucketSize* 1.5) = 3840`。

  * `shuffleBucketSize=32` 减少攒批桶数量，默认是 `128`。

  * `shuffleFlushIntervalMs=10` 加速推送到 sink 端。

* 增加 `sink.workerNum`，默认 `16`，最大可以调整到 `64`。

## 攒批相关参数

  <main id="notice" type='notice'>
    <h4>注意</h4>
    <p>攒批相关参数仅适用于非数据库目标端的增量同步链路。</p>
  </main>

参考 GC情况：

1. 在 GC 不严重时，在目的端能承受的范围能增加攒批能力。

2. 在 GC 验证时，减少攒批。

   * `maxRecordCapacity`：攒批队列最大数量，默认 `16000`。

   * `shuffleMinBatchSize`：攒批最小批次，默认 `20`。

   * `shuffleMaxBatchSize`：攒批最大批次，默认 `64`。

   * `shuffleFlushIntervalMs`：刷新时间，默认 `100ms`。

   * `shuffleBucketMaxInFlightBatchSize`：每个并发允许最多正在投递数量，增量默认 `1`，全量不限制。

   * `shuffleBucketSize`：允许最大攒批并发。

在 shuffleMaxBatchSize || shuffleFlushIntervalMs 达成的条件下即会投递（写入线程还具备写入能力）。

## 延迟所需的信息说明

如果您使用的是 OMS 3.4.0 及以上版本，提供在任务下执行 `./connector_utils.sh metrics` 的信息。

如果您使用的是 OMS 3.3.1 及以上的版本需要提供：

1. 链路类型：全量或增量

2. 目标端类型

3. Store 是否存在延迟

4. 当前配置参数

5. 当前 RPS：在 `metrics.log` 中查看 `sink.rps` 信息及 `sink_execute_time` 信息。

6. 当前中间队列数量：在 `metrics.log` 中查看 `batchAccumulate` 与 `recordAccumulate`、`ready_execute_batch_size` 和 `wait_dispatch_record_size`。

7. GC 情况：在 `task` 目录下使用 /opt/alibaba/java/bin/jstat -gcutil `cat task.pid` 1s 命令可以查看到每秒的 GC 情况。
