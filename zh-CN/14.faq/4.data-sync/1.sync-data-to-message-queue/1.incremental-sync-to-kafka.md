# 增量数据同步到 Kafka 的顺序问题

本文主要介绍 OMS 社区版将数据库增量数据同步至 Kafka 的保证消息顺序策略。

OMS 社区版 3.3.0-CE 以下版本支持在部署 OMS 社区版时，将 `config.yaml` 中的配置项 `partition.mode` 配置成 `one_partition` 或者 `hash` 来决定消息投递至 Kafka 的分区策略。OMS 社区版 3.3.0-CE 及以上版本，则支持用户在创建目标端为 Kafka 的数据同步项目时，选择 **分区规则** 为 `One` 或者 `Hash`。

* `One` 表示将所有数据投递到目标端 Kafka 的 0 号队列上。此时投递到目标端 0 号队列上的数据按照事务聚合（同一个事务的数据顺序同步完成之后，才会同步下一个事务的数据），并且保证事务间的顺序、以及事务内变更的顺序。

    该同步策略的好处是完全保证消息顺序，坏处是只能使用目标端的单个分区，数据同步项目的最大吞吐量会受 Kafka 单队列的吞吐限制。

* `Hash` 表示将源端的数据按照 **分片列**（如果不设置，默认会使用表的主键或非空唯一键作为分片列）的值 Hash 取模，将数据打散并发写入到目标端 Kafka 的多个队列上。

    在这种分区规则下，可以保证表内分片列值相同的数据变更同步到目标端 Kafka 的同一队列上，并保证这些数据变更的先后顺序和源端数据库提交的顺序一致。分片列值不同的数据变更由于 Hash 结果可能不同，投递到目标端无法保证在同一个队列上，也就无法保证下游对这些数据的消费顺序和源端数据库提交的顺序保持一致。即可能出现表的 A 变更先于 B 变更，但是 B 变更先于 A 变更写到目标端的情况。

    该策略的好处是在保证了同一条数据的多个变更顺序投递到目标端的情况下，可以利用目标端多队列提升链路最大吞吐。
