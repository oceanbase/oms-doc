# 创建 OceanBase 社区版至 Kafka 的数据同步项目

Kafka 是目前广泛应用的高性能分布式流计算平台，OceanBase 迁移服务（OceanBase Migration Service，OMS）社区版支持 OceanBase 社区版与自建 Kafka 数据源之间的数据实时同步，扩展消息处理能力，广泛应用于实时数据仓库搭建、数据查询和报表分流等业务场景。

OMS 社区版支持数据同步至消息队列产品，扩展业务在监控数据聚合、流式数据处理、在线和离线分析等大数据领域的全方位应用。同步 OceanBase 社区版的数据至 Kafka 时，对应的数据格式请参见 [数据格式说明](../700.data-synchronization/1200.sync-function-introduction/700.data-formats.md)。

## 前提条件

已为源端 OceanBase 社区版创建专用于数据同步项目的数据库用户，并为其赋予了相关权限。详情请参见 [创建数据库用户](../800.create-and-manage-data-sources/300.create-a-database-user.md)。

## 使用限制

* 数据同步的对象仅支持物理表，不支持其它对象。

* OMS 社区版支持 Kafka 0.9、1.0 和 2.x 版本。

  <main id="notice" type='notice'>
    <h4>注意</h4>
    <p>当 Kafka 版本为 0.9 时，不支持结构同步。</p>
  </main>

* 数据同步过程中，如果您在源端修改了同步范围内的表名称，且重命名后的名称不在同步对象中，则该部分数据将不被同步至目标 Kafka 实例中。

* 待同步的表名和其中的列名不能包含中文字符。

* 数据源标识和用户账号等，在 OMS 系统内全局唯一。

* OMS 社区版仅支持同步库名、表名和列名为 ASCII 码且不包含特殊字符（包括 .|"'`()=;/& 和换行）的对象。

* OMS 社区版不支持 OceanBase 备库作为源端。

## 注意事项

* 在源端为 OceanBase 社区版并开启同步 DDL 的数据同步项目中，如果源端库表发生重命名（`RENAME`）操作，建议您重新启动项目，避免增量同步丢失数据。

* 当更新的行包括 LOB 列时：

  * 如果 LOB 列为更新列，请勿依赖 LOB 列在 `UPDATE` 或 `DELETE` 操作前的值。

      目前使用 LOB 列进行存储的数据类型包括 JSON、GIS、XML、UDT（用户定义类型），以及 LONGTEXT、MEDIUMTEXT 等各类 TEXT。

  * 如果 LOB 列为非更新列，LOB 列在 `UPDATE` 或 `DELETE` 操作前或操作后的值均为 NULL。

* 节点之间的时钟不同步，或者电脑终端和服务器之间的时钟不同步，均可能导致增量同步的延迟时间不准确。

   例如，如果时钟早于标准时间，可能导致延迟时间为负数。如果时钟晚于标准时间，可能导致延迟。

* 当项目意外中断进行断点续传时，Kafka 实例中可能会存在部分重复数据（最近一分钟内），因此下游系统需要具备排重能力。

* 同步 OceanBase 社区版的数据至 Kafka 时，源端执行创建唯一索引语句失败，Kafka 会消费到创建 DDL 语句和删除 DDL 语句。如果传到下游的创建索引 DDL 执行失败，请忽略该异常。

  <main id="notice" type='notice'>
    <h4>注意</h4>
    <p>2.2.x 版本的 Liboblog 不能保证 DDL/DML 顺序，可能会存在数据质量问题。</p>
  </main>

## 同步 DDL 支持的范围

* 创建表 `CREATE TABLE`

  <main id="notice" type='notice'>
    <h4>注意</h4>
    <p>创建的表需要在同步对象范围之内。目前仅支持对已经同步的表进行 <code>DROP TABLE</code> 操作后，再执行 <code>CREATE TABLE</code>。</p>
  </main>

* 修改表 `ALTER TABLE`

* 删除表 `DROP TABLE`

* 清空表 `TRUNCATE TABLE`

   延迟删除场景下，同一个事务中会有两条一样的 `TRUNCATE TABLE` DDL。此时，下游消费需要按幂等方式处理。

* 从指定的分区中删除数据 `ALTER TABLE…TRUNCATE PARTITION`

* 创建索引 `CREATE INDEX`

* 删除索引 `DROP INDEX`

* 添加表的备注 `COMMENT ON TABLE`

* 表重命名 `RENAME TABLE`

  <main id="notice" type='notice'>
    <h4>注意</h4>
    <p>重命名后的表名需要在同步对象范围之内。</p>
  </main>

## 操作步骤

1. 新建数据同步项目。

   1. 登录 OMS 社区版控制台。

   2. 在左侧导航栏，单击 **数据同步**。

   3. 在 **数据同步** 页面，单击右上角的 **新建同步项目**。

2. 在 **选择源和目标** 页面，配置各项参数。

   |   参数   |                                                                         描述                                                                          |
   |--------|-----------------------------------------------------------------------------------------------------------------------------------------------------|
   | 同步项目名称 | 建议使用中文、数字和字母的组合。名称中不能包含空格，长度不能超过 64 个字符。                                                                                                            |
   | 标签（可选）     | 单击文本框，在下拉列表中选择目标标签。您也可以单击 **管理标签**，进行新建、修改和删除。详情请参见 [通过标签管理数据同步项目](1100.manage-a-data-synchronization-projects/300.use-tags-to-manage-data-synchronization-projects.md)。                                   |
   | 源端     | 如果您已新建 OceanBase-CE 数据源，请从下拉列表中进行选择。如果未新建，请单击下拉列表中的 **新建数据源**，在右侧对话框进行添加。参数详情请参见 [新建 OceanBase-CE 数据源](../800.create-and-manage-data-sources/100.create-a-data-source/100.add-an-oceanbase-ce-data-source.md)。 |
   | 目标端    | 如果您已新建 Kafka 数据源，请从下拉列表中进行选择。如果未新建，请单击下拉列表中的 **新建数据源**，在右侧对话框进行添加。参数详情请参见 [新建 Kafka 数据源](../800.create-and-manage-data-sources/100.create-a-data-source/500.create-a-kafka-data-source.md)。             |

3. 单击 **下一步**，在 **选择同步类型** 页面，选择当前数据同步项目的同步类型。

   同步类型包括 **结构同步**、**全量同步** 和 **增量同步**。**全量同步** 支持无主键表的同步，**增量同步** 支持 [同步 DML](1200.sync-function-introduction/100.sync-dml.md) 和 [同步 DDL](1200.sync-function-introduction/200.sync-ddl.md)。

4. （可选）单击 **下一步**。

   源端为 OceanBase 社区版时，结构迁移、增量同步需要配置 **所属 OCP**（可选）、**用户名** 和 **密码**。

   如果您选择了 **结构迁移**、**增量同步**，但源端 OceanBase 社区版未配置相应参数，则会弹出 **数据源补充信息** 对话框，提醒您进行配置。参数详情请参见 [新建 OceanBase-CE 数据源](../800.create-and-manage-data-sources/100.create-a-data-source/100.add-an-oceanbase-ce-data-source.md)。

   补充完成后，单击 **测试连通性**。测试连接成功后，单击 **保存**。

5. 单击 **下一步**，在 **选择同步对象** 页面，选择同步范围。

   同步 OceanBase 社区版的数据至 Kafka 时，支持多表到多 Topic 的同步。

   1. 在选择区域左侧选中需要同步的对象。

   2. 单击 **\>**。

   3. 在 **将对象映射至 Topic** 对话框中，选择需要的映射方式进行配置。

      如果设置同步类型时未选择 **结构同步**，则仅支持选择 **已有 Topic**。如果设置同步类型时已选择 **结构同步**，则仅支持选择一种映射方式进行 Topic 的创建或选择。

      例如，已选择结构同步的情况下，您使用了新建 Topic 和选择已有 Topic 两种映射方式，或通过重命名的方式更改了 Topic 的名称，会因为选项冲突导致预检查报错。

      |     参数     |                                                                 描述                                                                  |
      |------------|-------------------------------------------------------------------------------------------------------------------------------------|
      | 新建 Topic   | 在文本框中输入新建 Topic 的名称。支持 3\~64 位字符, 且只能包含英文、数字、短横线（-）、下划线（_）和英文句号（.）。                                                                 |
      | 选择 Topic   | OMS 社区版提供查询 Kafka Topic 的能力，您可以单击 **选择 Topic**，在 **已有 Topic** 下拉列表中，搜索并选中需要同步的 Topic。您也可以输入已有 Topic 后选中显示的 Topic 名称。 |
      | 批量生成 Topic | 批量生成 Topic 的规则为 `Topic_${Database Name}_${Table Name}`。                                                                             |

      如果您选择 **新建 Topic** 或 **批量生成 Topic**，结构同步成功后，在 Kafka 侧能够查询到新建的 Topic（分区数量默认为 3 个，分区副本数量默认为 1 个，且不支持修改）。如果不符合业务要求，请自行在目标端创建。

   4. 单击 **确定**。

   同步 OceanBase 社区版的数据至 Kafka 时，OMS 社区版支持通过文本导入对象，并支持对目标端对象进行更改 Topic、设置行过滤、移除单个对象或全部对象等操作。目标端对象的结构为 Topic\>DataBase\>Table。

   |    操作    |          步骤      |
   |----------|------------------------------------------------------------------------------------------------------------|
   | 导入对象     | <ol><li>在选择区域的右侧列表中，单击右上角的 **导入对象**。  <li> 在对话框中，单击 **确定**。 <br>**注意：**<br>  导入会覆盖之前的操作选择，请谨慎操作。   <li> 在 **导入同步对象** 对话框中，导入需要同步的对象。<br> 您可以通过导入 CSV 文件的方式进行库表重命名、设置行过滤条件等操作。详情请参见 [下载和导入同步对象配置](1100.manage-a-data-synchronization-projects/400.download-and-import-the-settings-of-synchronization-objects.md)。  <li> 单击 **检验合法性**。  <li> 通过合法性的检验后，单击 **确定**。  </ol>                              |
   | 更改 Topic | OMS 社区版支持对目标对象进行更改 Topic 操作。详情请参见 [更改 Topic](1200.sync-function-introduction/400.topic-rename.md)。                                                 |
   | 设置       | OMS 社区版支持配置行过滤、选择分片列和需要同步的列。<ol><li> 在选择区域的右侧列表中，鼠标悬停至目标对象。   <li> 单击显示的 **设置**。   <li> 在 **设置** 对话框中，您可以进行以下操作。 <ul><li> 在 **行过滤条件** 区域的文本框中，输入标准的 SQL 语句中的 `WHERE` 子句，来配置行过滤。详情请参见 [SQL 条件过滤数据](1200.sync-function-introduction/500.sync-row-filters.md)。   <li> 在 **分片列** 下拉列表中，选择目标分片列。您可以选择多个字段作为分片列，该参数为选填。 <br>选择分片列时，如果没有特殊情况，默认选择主键即可。如果存在主键负载不均衡的情况，请选择唯一性标识且负载相对均衡的字段作为分片列，避免潜在的性能问题。分片列的主要作用如下： <ul><li> 负载均衡：在目标端可以进行并发写入的情况下，通过分片列区分发送消息需要使用的特定线程。   <li> 有序性：由于存在并发写入可能导致的无序问题，OMS 社区版确保在分片列的值相同的情况下，用户接收到的消息是有序的。此处的有序是指变更顺序（DML 对于一列的执行顺序）。</ul><li> 在 **选择列** 区域，选择需要同步的列。详情请参见 [列过滤](1200.sync-function-introduction/600.sync-column-filters.md)。 </ul>       <li> 单击 **确定**。  </ol>  |
   | 移除/全部移除  | OMS 社区版支持在数据映射时，对暂时选中到目标端的单个或多个对象进行移除操作。<ul><li> 移除单个同步对象 <br>在选择区域的右侧列表中，鼠标悬停至目标对象，单击显示的 **移除**，即可移除该同步对象。   <li> 移除全部同步对象 <br>在选择区域的右侧列表中，单击右上角的 **全部移除**。在对话框中，单击 **确定**，即可移除全部同步对象。      |

6. 单击 **下一步**，在 **同步选项** 页面，配置各项参数。

   |     参数     |                            描述                             |
   |------------|-------------------------------------------------------------|
   | 增量同步起始位点   | <ul><li> 如果选择同步类型时已选择 **全量同步**，此处默认为项目启动时间，不支持修改。   <li> 如果选择同步类型时未选择 **全量同步**，请在此处指定同步某个时间节点之后的数据，默认为当前系统时间。您可以选择时间节点，也可以直接输入时间戳。<br> **注意：** <br> 仅支持选择当前时间，或当前时间之前的时间点。 该位点与当前归档日志的保留时间密切相关。如果无特殊要求，可以从当前位点开始启动。  </ul>       |
   | 序列化方式      | 控制数据同步至 Kafka 的消息格式，目前支持 **Default**、**Canal**、**Dataworks**（支持 2.0 版本）、**SharePlex**、**DefaultExtendColumnType**、**Debezium**、**DebeziumFlatten**、**Maxwell** 和 **DebeziumSmt**。详情请参见 [数据格式说明](1200.sync-function-introduction/700.data-formats.md)。  <br>**注意：**   <ul><li>目前仅 OceanBase 数据库 MySQL 租户支持 **Debezium**、**DebeziumFlatten** 和 **DebeziumSmt**。 <li>当选择 **Dataworks** 时，同步 DDL 不支持 `COMMENT ON TABLE` 和 `ALTER TABLE…TRUNCATE PARTITION`。                                                                                                                                      |
   | 分区规则       | 同步 OceanBase 数据库的数据至 Kafka Topic 的规则，目前支持 **Hash**、**Table** 和 **One**。 <ul><li> **Hash** 表示 OMS 社区版使用一定的 Hash 算法，根据主键值或分片列值 Hash 选择 Kafka Topic 的分区。<br>**注意：**<br>Hash 仅支持投递到所有的 partition 中。<li> **Table** 表示 OMS 社区版将一张表中的全部数据投递至同一个分区中，以表名作为 Hash 键。   <li> **One** 表示 JSON 消息会投递至 Topic 下的某个分区，目的是为了保持排序。</ul>    |
   | 业务系统标识（可选） | 用于标识数据的业务系统来源，以便您后续进行自定义处理。该业务系统标识的长度限制为 1\~20 个字符。              |

7. 单击 **预检查**。

   在 **预检查** 环节，OMS 社区版会检测和目标端 Kafka 实例的连接情况。如果预检查报错：

   * 您可以排查并处理问题后，重新执行预检查，直至预检查成功。

   * 您也可以单击错误预检查项操作列中的 **跳过**，会弹出对话框提示您跳过本操作的具体影响，确认可以跳过后，请单击对话框中的 **确定**。

8. 单击 **启动项目**。如果您暂时无需启动项目，请单击 **保存**，跳转至数据同步项目的详情页面，您可以根据需要手动启动数据同步项目。

   OMS 社区版支持在数据同步项目运行过程中修改同步对象，详情请参见 [查看和修改同步对象](1100.manage-a-data-synchronization-projects/200.view-and-modify-objects-to-be-synchronized.md)。数据同步项目启动后，会根据选择的同步类型依次执行，详情请参见 [查看数据同步项目的详情](1100.manage-a-data-synchronization-projects/100.view-details-of-a-data-synchronization-project.md) 中《查看同步详情》模块的内容。

   如果数据同步项目运行报错（通常由于网络不通或进程启动过慢导致），您可以在数据同步项目的列表或详情页面，单击 **恢复**。
